{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/meliksahb/Machine-Vision/blob/main/Deneme2.ipynb",
      "authorship_tag": "ABX9TyOMJMQCKNz1CAWEOsLuUiJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliksahb/Machine-Vision/blob/main/RF-Detr_and_Improved_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install requests supervision rfdetr opencv-python opencv-contrib-python matplotlib torch torchvision pillow numpy scikit-learn\n",
        "!unzip Images.zip\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "# Import RF-DETR components\n",
        "try:\n",
        "    from rfdetr import RFDETRBase, RFDETRLarge\n",
        "    from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "except ImportError:\n",
        "    print(\"Please install RF-DETR: pip install rfdetr\")\n",
        "    exit(1)"
      ],
      "metadata": {
        "id": "Djp7XGmzWhq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEPcCVz13Pyv"
      },
      "outputs": [],
      "source": [
        "class RFDETRExperimentalFramework:\n",
        "    \"\"\"\n",
        "    Experimental framework for RF‐DETR and a simpler fundamental CV pipeline.\n",
        "    Synthetic generation and JSON reporting have been removed.\n",
        "    The NMS in fundamental CV is the original single‐threshold `_simple_nms`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir=\"./rf_detr_experiments\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Initialize models\n",
        "        self.rf_detr_base = RFDETRBase()\n",
        "        self.rf_detr_large = RFDETRLarge()\n",
        "\n",
        "        # Placeholder results dictionary (not dumped to JSON here)\n",
        "        self.results = {\n",
        "            'rf_detr_base': {},\n",
        "            'rf_detr_improved': {},\n",
        "            'fundamental_cv': {},\n",
        "            'rf_detr_base_challenging': {},\n",
        "            'rf_detr_improved_challenging': {},\n",
        "            'fundamental_cv_challenging': {},\n",
        "            'rf_detr_base_camera': {},\n",
        "            'rf_detr_improved_camera': {},\n",
        "            'fundamental_cv_camera': {},\n",
        "            'rf_detr_base_folder': {},\n",
        "            'rf_detr_improved_folder': {},\n",
        "            'fundamental_cv_folder': {}\n",
        "        }\n",
        "\n",
        "        print(f\"[INIT] Experiment framework initialized. Output directory: {self.output_dir}\")\n",
        "\n",
        "    def load_test_images(self):\n",
        "        \"\"\"\n",
        "        Load standard test images for initial experiments.\n",
        "        \"\"\"\n",
        "        test_urls = [\n",
        "            \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\",\n",
        "            \"https://images.unsplash.com/photo-1544717297-fa95b6ee9643?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\"\n",
        "        ]\n",
        "\n",
        "        images = []\n",
        "        for i, url in enumerate(test_urls):\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "                images.append(img)\n",
        "                img.save(self.output_dir / f\"test_image_{i+1}.jpg\")\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Failed to load image from {url}: {e}\")\n",
        "\n",
        "        return images\n",
        "\n",
        "    def create_challenging_dataset(self):\n",
        "        \"\"\"\n",
        "        Create a challenging dataset designed to make RF-DETR fail.\n",
        "        \"\"\"\n",
        "        challenging_scenarios = [\n",
        "            # Small objects in cluttered scenes\n",
        "            \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Low contrast / lighting conditions\n",
        "            \"https://images.unsplash.com/photo-1518837695005-2083093ee35b?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Motion blur\n",
        "            \"https://images.unsplash.com/photo-1449824913935-59a10b8d2000?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Occlusion\n",
        "            \"https://images.unsplash.com/photo-1601758228041-f3b2795255f1?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\"\n",
        "        ]\n",
        "\n",
        "        challenging_images = []\n",
        "        for i, url in enumerate(challenging_scenarios):\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "                challenging_images.append(img)\n",
        "                img.save(self.output_dir / f\"challenging_image_{i+1}.jpg\")\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Failed to load challenging image from {url}: {e}\")\n",
        "\n",
        "        return challenging_images\n",
        "\n",
        "    def test_rf_detr_original(self, images, threshold=0.5, image_prefix=\"\"):\n",
        "        \"\"\"\n",
        "        Test original RF-DETR performance. Saves annotated images and records results.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            detections_base = self.rf_detr_large.predict(image, threshold=threshold)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            labels = [\n",
        "                f\"{COCO_CLASSES[class_id]} {conf:.2f}\"\n",
        "                for class_id, conf in zip(detections_base.class_id, detections_base.confidence)\n",
        "            ]\n",
        "\n",
        "            annotated_image = image.copy()\n",
        "            annotated_image = sv.BoxAnnotator().annotate(annotated_image, detections_base)\n",
        "            annotated_image = sv.LabelAnnotator().annotate(annotated_image, detections_base, labels)\n",
        "            annotated_image.save(self.output_dir / f\"rf_detr_original_{image_prefix}result_{i+1}.jpg\")\n",
        "\n",
        "            result = {\n",
        "                'image_id': i + 1,\n",
        "                'detections': int(len(detections_base.class_id)),\n",
        "                'inference_time': float(inference_time),\n",
        "                'confidence_scores': [float(c) for c in detections_base.confidence.tolist()] if len(detections_base.confidence) > 0 else [],\n",
        "                'classes_detected': [COCO_CLASSES[cid] for cid in detections_base.class_id] if len(detections_base.class_id) > 0 else []\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        if image_prefix == \"challenging_\":\n",
        "            self.results['rf_detr_base_challenging'] = results\n",
        "        elif image_prefix == \"camera_\":\n",
        "            self.results['rf_detr_base_camera'] = results\n",
        "        elif image_prefix == \"folder_\":\n",
        "            self.results['rf_detr_base_folder'] = results\n",
        "        else:\n",
        "            self.results['rf_detr_base'] = results\n",
        "\n",
        "        return results\n",
        "\n",
        "    def implement_rf_detr_improvements(self, images, image_prefix=\"\"):\n",
        "        \"\"\"\n",
        "        Implement improved RF-DETR (test-time augmentation + confidence calibration + weighted voting + class NMS).\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            orig_w, orig_h = image.size\n",
        "            augmented_predictions = []\n",
        "\n",
        "            # 1) Original large model\n",
        "            det_orig = self.rf_detr_large.predict(image, threshold=0.4)\n",
        "            augmented_predictions.append(('orig', det_orig, 1.0))\n",
        "\n",
        "            # 2) Horizontal flip\n",
        "            img_flipped = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            det_flipped = self.rf_detr_large.predict(img_flipped, threshold=0.4)\n",
        "            if len(det_flipped.xyxy) > 0:\n",
        "                flipped_boxes = det_flipped.xyxy.copy()\n",
        "                flipped_boxes[:, [0, 2]] = orig_w - det_flipped.xyxy[:, [2, 0]]\n",
        "                det_flipped.xyxy = flipped_boxes\n",
        "                augmented_predictions.append(('flip', det_flipped, 0.9))\n",
        "\n",
        "            # 3) Two more thresholds\n",
        "            for thresh in [0.3, 0.5]:\n",
        "                det_t = self.rf_detr_large.predict(image, threshold=thresh)\n",
        "                weight = 0.7 if thresh == 0.3 else 0.8\n",
        "                augmented_predictions.append((f'thresh_{thresh}', det_t, weight))\n",
        "\n",
        "            # Combine everything\n",
        "            all_boxes = []\n",
        "            all_scores = []\n",
        "            all_classes = []\n",
        "            all_weights = []\n",
        "\n",
        "            for aug_type, det, weight in augmented_predictions:\n",
        "                if len(det.xyxy) > 0:\n",
        "                    all_boxes.append(det.xyxy)\n",
        "                    calibrated = self._calibrate_confidence(det.confidence)\n",
        "                    all_scores.append(calibrated * weight)\n",
        "                    all_classes.append(det.class_id)\n",
        "                    all_weights.append(np.full(len(det.confidence), weight))\n",
        "\n",
        "            if all_boxes:\n",
        "                all_boxes = np.vstack(all_boxes)\n",
        "                all_scores = np.concatenate(all_scores)\n",
        "                all_classes = np.concatenate(all_classes)\n",
        "                all_weights = np.concatenate(all_weights)\n",
        "\n",
        "                # Class-specific NMS → gather final detections\n",
        "                final_boxes, final_scores, final_classes = [], [], []\n",
        "                for cls in np.unique(all_classes):\n",
        "                    mask = (all_classes == cls)\n",
        "                    boxes_cls = all_boxes[mask]\n",
        "                    scores_cls = all_scores[mask]\n",
        "                    det_temp = sv.Detections(\n",
        "                        xyxy=boxes_cls,\n",
        "                        confidence=scores_cls,\n",
        "                        class_id=np.full(len(boxes_cls), cls, dtype=int)\n",
        "                    )\n",
        "                    det_nms = det_temp.with_nms(threshold=0.5)\n",
        "                    if len(det_nms.xyxy) > 0:\n",
        "                        final_boxes.append(det_nms.xyxy)\n",
        "                        final_scores.append(det_nms.confidence)\n",
        "                        final_classes.append(det_nms.class_id)\n",
        "\n",
        "                if final_boxes:\n",
        "                    final_boxes = np.vstack(final_boxes)\n",
        "                    final_scores = np.concatenate(final_scores)\n",
        "                    final_classes = np.concatenate(final_classes)\n",
        "\n",
        "                    mask_keep = final_scores >= 0.5\n",
        "                    final_detections = sv.Detections(\n",
        "                        xyxy=final_boxes[mask_keep],\n",
        "                        confidence=final_scores[mask_keep],\n",
        "                        class_id=final_classes[mask_keep].astype(int)\n",
        "                    )\n",
        "                else:\n",
        "                    final_detections = sv.Detections.empty()\n",
        "            else:\n",
        "                final_detections = sv.Detections.empty()\n",
        "\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            labels = [\n",
        "                f\"{COCO_CLASSES[cid]} {conf:.2f}\"\n",
        "                for cid, conf in zip(final_detections.class_id, final_detections.confidence)\n",
        "            ]\n",
        "\n",
        "            annotated_image = image.copy()\n",
        "            if len(final_detections) > 0:\n",
        "                annotated_image = sv.BoxAnnotator(color_lookup=sv.ColorLookup.CLASS).annotate(annotated_image, final_detections)\n",
        "                annotated_image = sv.LabelAnnotator().annotate(annotated_image, final_detections, labels)\n",
        "\n",
        "            annotated_image.save(self.output_dir / f\"rf_detr_improved_{image_prefix}result_{i+1}.jpg\")\n",
        "\n",
        "            result = {\n",
        "                'image_id': i + 1,\n",
        "                'detections': int(len(final_detections.class_id)),\n",
        "                'inference_time': float(inference_time),\n",
        "                'confidence_scores': [float(c) for c in final_detections.confidence.tolist()] if len(final_detections.confidence) > 0 else [],\n",
        "                'classes_detected': [COCO_CLASSES[cid] for cid in final_detections.class_id] if len(final_detections.class_id) > 0 else [],\n",
        "                'improvements_applied': ['tta', 'conf_calibration', 'class_nms', 'voting']\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        if image_prefix == \"challenging_\":\n",
        "            self.results['rf_detr_improved_challenging'] = results\n",
        "        elif image_prefix == \"camera_\":\n",
        "            self.results['rf_detr_improved_camera'] = results\n",
        "        elif image_prefix == \"folder_\":\n",
        "            self.results['rf_detr_improved_folder'] = results\n",
        "        else:\n",
        "            self.results['rf_detr_improved'] = results\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _calibrate_confidence(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Temperature scaling on confidence scores.\n",
        "        \"\"\"\n",
        "        temperature = 1.5\n",
        "        calibrated = scores ** (1.0 / temperature)\n",
        "        if len(calibrated) > 0 and calibrated.max() > 0:\n",
        "            calibrated = calibrated / calibrated.max() * scores.max()\n",
        "        return calibrated\n",
        "\n",
        "    def implement_fundamental_cv_techniques(self, images, image_prefix=\"\"):\n",
        "        \"\"\"\n",
        "        Fundamental CV pipeline with a single-threshold NMS (_simple_nms).\n",
        "        Detectors used:\n",
        "         1) HOG+SVM for full-body (person)\n",
        "         2) Combined Otsu + adaptive threshold contouring\n",
        "         3) Canny edges\n",
        "         4) Color segmentation (HSV)\n",
        "         5) SIFT + DBSCAN (textured objects)\n",
        "         6) Selective Search on large images only\n",
        "        Finally: apply `_simple_nms`.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        # Initialize HOG person detector (more robust than Haar cascades)\n",
        "        hog = cv2.HOGDescriptor()\n",
        "        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "            h, w = img_cv.shape[:2]\n",
        "\n",
        "            detections_found = []\n",
        "\n",
        "            # 1) HOG+SVM person detections\n",
        "            hog_rects, hog_weights = hog.detectMultiScale(\n",
        "                img_gray,\n",
        "                winStride=(8, 8),\n",
        "                padding=(8, 8),\n",
        "                scale=1.05\n",
        "            )\n",
        "            for (x, y, ww, hh), weight in zip(hog_rects, hog_weights):\n",
        "                if weight > 0.5:\n",
        "                    detections_found.append({\n",
        "                        'bbox': [x, y, x + ww, y + hh],\n",
        "                        'class': 'person',\n",
        "                        'confidence': float(weight),\n",
        "                        'method': 'HOG'\n",
        "                    })\n",
        "\n",
        "            # 2) Combined Otsu + adaptive threshold → composite mask\n",
        "            blurred = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
        "            _, otsu_mask = cv2.threshold(\n",
        "                blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
        "            )\n",
        "            adapt_mask = cv2.adaptiveThreshold(\n",
        "                blurred, 255,\n",
        "                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                cv2.THRESH_BINARY, 11, 2\n",
        "            )\n",
        "            composite_mask = cv2.bitwise_or(otsu_mask, adapt_mask)\n",
        "\n",
        "            # Morphological closing/opening to clean noise\n",
        "            kernel_close = np.ones((7, 7), np.uint8)\n",
        "            kernel_open = np.ones((3, 3), np.uint8)\n",
        "            composite_mask = cv2.morphologyEx(\n",
        "                composite_mask, cv2.MORPH_CLOSE, kernel_close, iterations=2\n",
        "            )\n",
        "            composite_mask = cv2.morphologyEx(\n",
        "                composite_mask, cv2.MORPH_OPEN, kernel_open, iterations=1\n",
        "            )\n",
        "\n",
        "            contours_oa, _ = cv2.findContours(\n",
        "                composite_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "            )\n",
        "            for cnt in contours_oa:\n",
        "                area = cv2.contourArea(cnt)\n",
        "                if area < 1200:\n",
        "                    continue\n",
        "                x, y, ww, hh = cv2.boundingRect(cnt)\n",
        "                aspect = ww / float(hh)\n",
        "                if not (0.4 < aspect < 2.5):\n",
        "                    continue\n",
        "                hull = cv2.convexHull(cnt)\n",
        "                hull_area = cv2.contourArea(hull)\n",
        "                solidity = float(area) / hull_area if hull_area > 0 else 0\n",
        "                if solidity < 0.8:\n",
        "                    continue\n",
        "                detections_found.append({\n",
        "                    'bbox': [x, y, x + ww, y + hh],\n",
        "                    'class': 'object',\n",
        "                    'confidence': float(min(0.75, solidity)),\n",
        "                    'method': 'OtsuAdaptive'\n",
        "                })\n",
        "\n",
        "            # 3) Canny edges\n",
        "            v_median = np.median(img_gray)\n",
        "            lower_c = int(max(0, (1.0 - 0.33) * v_median))\n",
        "            upper_c = int(min(255, (1.0 + 0.33) * v_median))\n",
        "            edges = cv2.Canny(blurred, lower_c, upper_c)\n",
        "            edges_closed = cv2.morphologyEx(\n",
        "                edges, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8), iterations=1\n",
        "            )\n",
        "            cnts_e, _ = cv2.findContours(\n",
        "                edges_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "            )\n",
        "            for cnt in cnts_e:\n",
        "                area = cv2.contourArea(cnt)\n",
        "                if area < 800:\n",
        "                    continue\n",
        "                x, y, ww, hh = cv2.boundingRect(cnt)\n",
        "                if not (ww > 30 and hh > 30 and ww < w * 0.8 and hh < h * 0.8):\n",
        "                    continue\n",
        "                detections_found.append({\n",
        "                    'bbox': [x, y, x + ww, y + hh],\n",
        "                    'class': 'edge_object',\n",
        "                    'confidence': 0.55,\n",
        "                    'method': 'Canny'\n",
        "                })\n",
        "\n",
        "            # 4) Color segmentation (HSV) with tuned ranges\n",
        "            hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)\n",
        "            color_ranges = {\n",
        "                'skin': ([0, 48, 80], [20, 255, 255]),\n",
        "                'red_object': ([0, 100, 100], [10, 255, 255]),\n",
        "                'blue_object': ([100, 150, 0], [140, 255, 255]),\n",
        "                'green_object': ([40, 40, 40], [80, 255, 255]),\n",
        "                'yellow_object': ([15, 150, 150], [35, 255, 255])\n",
        "            }\n",
        "            for name, (lower, upper) in color_ranges.items():\n",
        "                low = np.array(lower, dtype=np.uint8)\n",
        "                high = np.array(upper, dtype=np.uint8)\n",
        "                mask_c = cv2.inRange(hsv, low, high)\n",
        "                mask_c = cv2.morphologyEx(\n",
        "                    mask_c, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8), iterations=1\n",
        "                )\n",
        "                mask_c = cv2.morphologyEx(\n",
        "                    mask_c, cv2.MORPH_CLOSE, np.ones((7, 7), np.uint8), iterations=2\n",
        "                )\n",
        "                cnts_c, _ = cv2.findContours(\n",
        "                    mask_c, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "                )\n",
        "                for cnt in cnts_c:\n",
        "                    area = cv2.contourArea(cnt)\n",
        "                    if area < 600:\n",
        "                        continue\n",
        "                    x, y, ww, hh = cv2.boundingRect(cnt)\n",
        "                    if not (ww > 30 and hh > 30 and ww < w * 0.7 and hh < h * 0.7):\n",
        "                        continue\n",
        "                    class_label = 'person' if name == 'skin' else 'object'\n",
        "                    detections_found.append({\n",
        "                        'bbox': [x, y, x + ww, y + hh],\n",
        "                        'class': class_label,\n",
        "                        'confidence': float(min(0.7, area / 12000)),\n",
        "                        'method': 'ColorSeg'\n",
        "                    })\n",
        "\n",
        "            # 5) SIFT + DBSCAN (textured objects)\n",
        "            try:\n",
        "                sift = cv2.SIFT_create()\n",
        "                kp, des = sift.detectAndCompute(img_gray, None)\n",
        "                if des is not None and len(kp) > 25:\n",
        "                    pts = np.float32([pt.pt for pt in kp])\n",
        "                    from sklearn.cluster import DBSCAN\n",
        "                    eps_val = min(w, h) * 0.08\n",
        "                    clustering = DBSCAN(eps=eps_val, min_samples=8).fit(pts)\n",
        "                    for cluster_id in set(clustering.labels_):\n",
        "                        if cluster_id < 0:\n",
        "                            continue\n",
        "                        pts_cluster = pts[clustering.labels_ == cluster_id]\n",
        "                        x_min, y_min = pts_cluster.min(axis=0)\n",
        "                        x_max, y_max = pts_cluster.max(axis=0)\n",
        "                        ww = x_max - x_min\n",
        "                        hh = y_max - y_min\n",
        "                        area = ww * hh\n",
        "                        if ww > 50 and hh > 50 and area > 3000:\n",
        "                            cnt = np.array([[int(px), int(py)] for px, py in pts_cluster.reshape(-1, 2)])\n",
        "                            hull = cv2.convexHull(cnt)\n",
        "                            hull_area = cv2.contourArea(hull)\n",
        "                            solidity = float(area) / hull_area if hull_area > 0 else 0\n",
        "                            if solidity > 0.75:\n",
        "                                detections_found.append({\n",
        "                                    'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],\n",
        "                                    'class': 'textured_object',\n",
        "                                    'confidence': 0.65,\n",
        "                                    'method': 'SIFT'\n",
        "                                })\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            # 6) Selective Search (only if image is large)\n",
        "            if max(w, h) > 512:\n",
        "                try:\n",
        "                    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "                    ss.setBaseImage(img_cv)\n",
        "                    ss.switchToSelectiveSearchFast()\n",
        "                    rects = ss.process()[:80]\n",
        "                    for (x, y, ww, hh) in rects:\n",
        "                        if ww < 60 or hh < 60 or ww > w * 0.7 or hh > h * 0.7:\n",
        "                            continue\n",
        "                        aspect = ww / float(hh)\n",
        "                        if not (0.5 < aspect < 2.0):\n",
        "                            continue\n",
        "                        region = img_gray[y : y + hh, x : x + ww]\n",
        "                        edge_density = cv2.Canny(region, 50, 150).mean()\n",
        "                        if edge_density > 18:\n",
        "                            detections_found.append({\n",
        "                                'bbox': [x, y, x + ww, y + hh],\n",
        "                                'class': 'object',\n",
        "                                'confidence': float(min(0.6, edge_density / 120)),\n",
        "                                'method': 'SelectiveSearch'\n",
        "                            })\n",
        "                except Exception:\n",
        "                    print(\"[WARN] Selective Search unavailable (opencv-contrib-python missing).\")\n",
        "\n",
        "            # Final: run the simple NMS (single IoU threshold)\n",
        "            if detections_found:\n",
        "                boxes = np.array([d['bbox'] for d in detections_found])\n",
        "                scores = np.array([d['confidence'] for d in detections_found])\n",
        "                keep_indices = self._simple_nms(boxes, scores, iou_threshold=0.3)\n",
        "                detections_found = [detections_found[idx] for idx in keep_indices]\n",
        "\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            # Visualize\n",
        "            img_vis = img_cv.copy()\n",
        "            method_colors = {\n",
        "                'HOG': (0, 255, 0),\n",
        "                'OtsuAdaptive': (255, 0, 0),\n",
        "                'Canny': (255, 255, 0),\n",
        "                'ColorSeg': (0, 255, 255),\n",
        "                'SIFT': (128, 0, 128),\n",
        "                'SelectiveSearch': (255, 0, 255),\n",
        "            }\n",
        "            for det in detections_found:\n",
        "                x1, y1, x2, y2 = map(int, det['bbox'])\n",
        "                color = method_colors.get(det['method'], (200, 200, 200))\n",
        "                cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(\n",
        "                    img_vis,\n",
        "                    f\"{det['class']}({det['method']}) {det['confidence']:.2f}\",\n",
        "                    (x1, y1 - 8),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    color,\n",
        "                    1,\n",
        "                    lineType=cv2.LINE_AA\n",
        "                )\n",
        "\n",
        "            img_vis_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
        "            result_pil = Image.fromarray(img_vis_rgb)\n",
        "            result_pil.save(self.output_dir / f\"fundamental_cv_{image_prefix}result_{i+1}.jpg\")\n",
        "\n",
        "            counts = Counter([d['method'] for d in detections_found])\n",
        "            result = {\n",
        "                'image_id': i + 1,\n",
        "                'detections': len(detections_found),\n",
        "                'inference_time': float(inference_time),\n",
        "                'detections_by_method': dict(counts)\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        if image_prefix == \"challenging_\":\n",
        "            self.results['fundamental_cv_challenging'] = results\n",
        "        elif image_prefix == \"camera_\":\n",
        "            self.results['fundamental_cv_camera'] = results\n",
        "        elif image_prefix == \"folder_\":\n",
        "            self.results['fundamental_cv_folder'] = results\n",
        "        else:\n",
        "            self.results['fundamental_cv'] = results\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _simple_nms(self, boxes, scores, iou_threshold=0.3):\n",
        "        \"\"\"\n",
        "        A basic IoU‐based Non‐Maximum Suppression (NMS) implementation.\n",
        "        - If zero boxes: return [].\n",
        "        - If one box: return [0].\n",
        "        - Otherwise, perform standard IoU‐thresholding.\n",
        "        \"\"\"\n",
        "        if boxes.size == 0:\n",
        "            return []\n",
        "        # If there's only one bounding box (shape (4,) or (1,4)), return [0] directly\n",
        "        if boxes.ndim == 1 or boxes.shape[0] == 1:\n",
        "            return [0]\n",
        "\n",
        "        x1 = boxes[:, 0]\n",
        "        y1 = boxes[:, 1]\n",
        "        x2 = boxes[:, 2]\n",
        "        y2 = boxes[:, 3]\n",
        "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "        order = scores.argsort()[::-1]\n",
        "\n",
        "        keep = []\n",
        "        while order.size > 0:\n",
        "            i = order[0]\n",
        "            keep.append(i)\n",
        "\n",
        "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "            inter = w * h\n",
        "\n",
        "            iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)\n",
        "            inds = np.where(iou <= iou_threshold)[0]\n",
        "            order = order[inds + 1]\n",
        "\n",
        "        return keep\n",
        "\n",
        "    def load_camera_images(self, num_frames=5, delay=0.5):\n",
        "        \"\"\"\n",
        "        Capture a few frames from the default webcam.\n",
        "        \"\"\"\n",
        "        camera_images = []\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        if not cap.isOpened():\n",
        "            print(\"[WARN] Could not open camera.\")\n",
        "            return camera_images\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(f\"[WARN] Could not read frame {i+1} from camera.\")\n",
        "                break\n",
        "\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = Image.fromarray(frame_rgb)\n",
        "            pil_img.save(self.output_dir / f\"camera_image_{i+1}.jpg\")\n",
        "            camera_images.append(pil_img)\n",
        "\n",
        "            time.sleep(delay)\n",
        "\n",
        "        cap.release()\n",
        "        return camera_images\n",
        "\n",
        "    def load_images_from_folder(self, folder_path):\n",
        "        \"\"\"\n",
        "        Load all images from a given folder (jpg, jpeg, png, bmp, tiff).\n",
        "        \"\"\"\n",
        "        folder = Path(folder_path)\n",
        "        loaded_images = []\n",
        "        if not folder.exists() or not folder.is_dir():\n",
        "            print(f\"[ERROR] Folder {folder_path} does not exist or is not a directory.\")\n",
        "            return loaded_images\n",
        "\n",
        "        for img_path in folder.glob(\"*\"):\n",
        "            if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]:\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert('RGB')\n",
        "                    loaded_images.append(img)\n",
        "                except Exception as e:\n",
        "                    print(f\"[WARN] Failed to load {img_path.name}: {e}\")\n",
        "        return loaded_images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Main Execution -----------------\n",
        "if __name__ == \"__main__\":\n",
        "    framework = RFDETRExperimentalFramework(output_dir=\"./rf_detr_experiments\")\n",
        "\n",
        "    # 1. Load standard test images\n",
        "    test_images = framework.load_test_images()\n",
        "\n",
        "    # 2. Create challenging dataset\n",
        "    challenging_images = framework.create_challenging_dataset()\n",
        "\n",
        "    # 3. Capture camera images (requires a connected webcam)\n",
        "    camera_images = framework.load_camera_images(num_frames=5, delay=0.5)\n",
        "\n",
        "    # 4. Load images from a user-specified folder\n",
        "    folder_path = \"/content/Images\"\n",
        "    folder_images = framework.load_images_from_folder(folder_path)\n",
        "\n",
        "    # 5. Run RF-DETR original on all sets\n",
        "    print(\"[RUN] RF-DETR original on standard test images...\")\n",
        "    framework.test_rf_detr_original(test_images, threshold=0.5, image_prefix=\"standard_\")\n",
        "\n",
        "    print(\"[RUN] RF-DETR original on challenging images...\")\n",
        "    framework.test_rf_detr_original(challenging_images, threshold=0.5, image_prefix=\"challenging_\")\n",
        "\n",
        "    if camera_images:\n",
        "        print(\"[RUN] RF-DETR original on camera images...\")\n",
        "        framework.test_rf_detr_original(camera_images, threshold=0.5, image_prefix=\"camera_\")\n",
        "\n",
        "    if folder_images:\n",
        "        print(f\"[RUN] RF-DETR original on folder images from {folder_path}...\")\n",
        "        framework.test_rf_detr_original(folder_images, threshold=0.5, image_prefix=\"folder_\")\n",
        "\n",
        "    # 6. Run RF-DETR improved\n",
        "    print(\"[RUN] RF-DETR improved on standard test images...\")\n",
        "    framework.implement_rf_detr_improvements(test_images, image_prefix=\"standard_\")\n",
        "\n",
        "    print(\"[RUN] RF-DETR improved on challenging images...\")\n",
        "    framework.implement_rf_detr_improvements(challenging_images, image_prefix=\"challenging_\")\n",
        "\n",
        "    if camera_images:\n",
        "        print(\"[RUN] RF-DETR improved on camera images...\")\n",
        "        framework.implement_rf_detr_improvements(camera_images, image_prefix=\"camera_\")\n",
        "\n",
        "    if folder_images:\n",
        "        print(f\"[RUN] RF-DETR improved on folder images from {folder_path}...\")\n",
        "        framework.implement_rf_detr_improvements(folder_images, image_prefix=\"folder_\")\n",
        "\n",
        "    # 7. Run fundamental CV techniques on all sets\n",
        "    print(\"[RUN] Fundamental CV on standard test images...\")\n",
        "    framework.implement_fundamental_cv_techniques(test_images, image_prefix=\"standard_\")\n",
        "\n",
        "    print(\"[RUN] Fundamental CV on challenging images...\")\n",
        "    framework.implement_fundamental_cv_techniques(challenging_images, image_prefix=\"challenging_\")\n",
        "\n",
        "    if camera_images:\n",
        "        print(\"[RUN] Fundamental CV on camera images...\")\n",
        "        framework.implement_fundamental_cv_techniques(camera_images, image_prefix=\"camera_\")\n",
        "\n",
        "    if folder_images:\n",
        "        print(f\"[RUN] Fundamental CV on folder images from {folder_path}...\")\n",
        "        framework.implement_fundamental_cv_techniques(folder_images, image_prefix=\"folder_\")\n",
        "\n",
        "    print(\"[DONE] All experiments completed.\")"
      ],
      "metadata": {
        "id": "O0McaF1T3SVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results.zip /content/rf_detr_experiments"
      ],
      "metadata": {
        "id": "D9LKbUuhgPuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkFUMP2d2nih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}