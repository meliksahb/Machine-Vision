{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7894p3yxZo4akRDcMMU10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliksahb/Machine-Vision/blob/main/MachineVisionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lTii3DK_iiLs",
        "outputId": "95d155f4-f014-4d92-c1be-4c7d9064f5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.25.1\n",
            "Please install RF-DETR: pip install rfdetr\n",
            "Step 1: Installing requirements...\n",
            "\n",
            "Step 2: Creating project structure...\n",
            "Created directory: rf_detr_experiments\n",
            "Created directory: custom_camera_dataset\n",
            "Created directory: results\n",
            "Created directory: plots\n",
            "Created directory: reports\n",
            "\n",
            "Step 3: Running main experiment...\n",
            "RF-DETR Comprehensive Analysis Project\n",
            "=====================================\n",
            "\n",
            "This project will:\n",
            "1. Test RF-DETR on standard images\n",
            "2. Implement improvements to RF-DETR\n",
            "3. Compare with fundamental CV techniques\n",
            "4. Create challenging dataset to find failures\n",
            "5. Generate comprehensive analysis with 4 required plots\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RFDETRBase' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d2a4b70edf82>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStep 3: Running main experiment...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStep 4: Displaying explanations...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d2a4b70edf82>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0;31m# Initialize experiment framework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFDETRExperimentalFramework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# Run complete experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d2a4b70edf82>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Initialize models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrf_detr_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFDETRBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrf_detr_large\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFDETRLarge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RFDETRBase' is not defined"
          ]
        }
      ],
      "source": [
        "# RF-DETR Computer Vision Project Implementation\n",
        "# This comprehensive project analyzes RF-DETR, implements improvements, and compares with fundamental CV techniques\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "! pip install supervision\n",
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Install required packages\n",
        "\"\"\"\n",
        "pip install rfdetr\n",
        "pip install supervision\n",
        "pip install opencv-python\n",
        "pip install matplotlib\n",
        "pip install torch torchvision\n",
        "pip install pillow\n",
        "pip install requests\n",
        "\"\"\"\n",
        "\n",
        "# Import RF-DETR components\n",
        "try:\n",
        "    from rfdetr import RFDETRBase, RFDETRLarge\n",
        "    from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "except ImportError:\n",
        "    print(\"Please install RF-DETR: pip install rfdetr\")\n",
        "    exit(1)\n",
        "\n",
        "class RFDETRExperimentalFramework:\n",
        "    \"\"\"\n",
        "    Comprehensive experimental framework for RF-DETR analysis, improvement, and comparison\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir=\"./rf_detr_experiments\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Initialize models\n",
        "        self.rf_detr_base = RFDETRBase()\n",
        "        self.rf_detr_large = RFDETRLarge()\n",
        "\n",
        "        # Results storage\n",
        "        self.results = {\n",
        "            'original': {},\n",
        "            'rf_detr_base': {},\n",
        "            'rf_detr_improved': {},\n",
        "            'fundamental_cv': {}\n",
        "        }\n",
        "\n",
        "        # Performance metrics\n",
        "        self.performance_metrics = []\n",
        "\n",
        "        print(f\"Experiment framework initialized. Output directory: {self.output_dir}\")\n",
        "\n",
        "    def load_test_images(self):\n",
        "        \"\"\"\n",
        "        Load standard test images for initial experiments\n",
        "        \"\"\"\n",
        "        test_urls = [\n",
        "            \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\",\n",
        "            \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/COCO_val2014_000000581781.jpg/640px-COCO_val2014_000000581781.jpg\",\n",
        "            \"https://images.unsplash.com/photo-1544717297-fa95b6ee9643?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\"\n",
        "        ]\n",
        "\n",
        "        images = []\n",
        "        for i, url in enumerate(test_urls):\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "                images.append(img)\n",
        "                # Save original image\n",
        "                img.save(self.output_dir / f\"test_image_{i+1}.jpg\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load image from {url}: {e}\")\n",
        "\n",
        "        return images\n",
        "\n",
        "    def create_challenging_dataset(self):\n",
        "        \"\"\"\n",
        "        Create a challenging dataset designed to make RF-DETR fail\n",
        "        This addresses the requirement to find algorithm failures\n",
        "        \"\"\"\n",
        "        challenging_scenarios = [\n",
        "            # Small objects in cluttered scenes\n",
        "            \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Low contrast/lighting conditions\n",
        "            \"https://images.unsplash.com/photo-1518837695005-2083093ee35b?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Motion blur\n",
        "            \"https://images.unsplash.com/photo-1449824913935-59a10b8d2000?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\",\n",
        "            # Occlusion\n",
        "            \"https://images.unsplash.com/photo-1601758228041-f3b2795255f1?ixlib=rb-4.0.3&auto=format&fit=crop&w=1000&q=80\"\n",
        "        ]\n",
        "\n",
        "        challenging_images = []\n",
        "        for i, url in enumerate(challenging_scenarios):\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "                challenging_images.append(img)\n",
        "                img.save(self.output_dir / f\"challenging_image_{i+1}.jpg\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load challenging image from {url}: {e}\")\n",
        "\n",
        "        return challenging_images\n",
        "\n",
        "    def test_rf_detr_original(self, images, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Test original RF-DETR performance\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            # RF-DETR Base prediction\n",
        "            detections_base = self.rf_detr_base.predict(image, threshold=threshold)\n",
        "\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            # Create visualization\n",
        "            labels = [\n",
        "                f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
        "                for class_id, confidence in zip(detections_base.class_id, detections_base.confidence)\n",
        "            ]\n",
        "\n",
        "            annotated_image = image.copy()\n",
        "            annotated_image = sv.BoxAnnotator().annotate(annotated_image, detections_base)\n",
        "            annotated_image = sv.LabelAnnotator().annotate(annotated_image, detections_base, labels)\n",
        "\n",
        "            # Save result\n",
        "            annotated_image.save(self.output_dir / f\"rf_detr_original_result_{i+1}.jpg\")\n",
        "\n",
        "            result = {\n",
        "                'image_id': i+1,\n",
        "                'detections': len(detections_base.class_id),\n",
        "                'inference_time': inference_time,\n",
        "                'confidence_scores': detections_base.confidence.tolist() if len(detections_base.confidence) > 0 else [],\n",
        "                'classes_detected': [COCO_CLASSES[cid] for cid in detections_base.class_id] if len(detections_base.class_id) > 0 else []\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        self.results['rf_detr_base'] = results\n",
        "        return results\n",
        "\n",
        "    def implement_rf_detr_improvements(self, images):\n",
        "        \"\"\"\n",
        "        Implement improvements to RF-DETR based on analysis\n",
        "        Improvements include:\n",
        "        1. Multi-scale testing\n",
        "        2. Ensemble of different model sizes\n",
        "        3. Dynamic threshold adjustment\n",
        "        4. Post-processing enhancements\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Multi-scale testing\n",
        "            scales = [560, 672, 784]  # Different input resolutions\n",
        "            ensemble_detections = []\n",
        "\n",
        "            for scale in scales:\n",
        "                # Resize image for different scales\n",
        "                img_array = np.array(image)\n",
        "                resized_img = cv2.resize(img_array, (scale, scale))\n",
        "                resized_pil = Image.fromarray(resized_img)\n",
        "\n",
        "                # Get detections from both models\n",
        "                det_base = self.rf_detr_base.predict(resized_pil, threshold=0.3)  # Lower threshold\n",
        "                det_large = self.rf_detr_large.predict(resized_pil, threshold=0.3)\n",
        "\n",
        "                ensemble_detections.extend([\n",
        "                    (det_base, 'base', scale),\n",
        "                    (det_large, 'large', scale)\n",
        "                ])\n",
        "\n",
        "            # Ensemble fusion with Non-Maximum Suppression\n",
        "            all_boxes = []\n",
        "            all_scores = []\n",
        "            all_classes = []\n",
        "\n",
        "            for detections, model_type, scale in ensemble_detections:\n",
        "                if len(detections.xyxy) > 0:\n",
        "                    # Scale boxes back to original image size\n",
        "                    boxes = detections.xyxy * (640 / scale)  # Assuming 640x640 base size\n",
        "                    all_boxes.extend(boxes.tolist())\n",
        "                    all_scores.extend(detections.confidence.tolist())\n",
        "                    all_classes.extend(detections.class_id.tolist())\n",
        "\n",
        "            # Apply NMS to ensemble results\n",
        "            if all_boxes:\n",
        "                all_boxes = np.array(all_boxes)\n",
        "                all_scores = np.array(all_scores)\n",
        "                all_classes = np.array(all_classes)\n",
        "\n",
        "                # Dynamic threshold based on score distribution\n",
        "                dynamic_threshold = max(0.4, np.percentile(all_scores, 70))\n",
        "\n",
        "                # Filter by dynamic threshold\n",
        "                valid_indices = all_scores >= dynamic_threshold\n",
        "                final_boxes = all_boxes[valid_indices]\n",
        "                final_scores = all_scores[valid_indices]\n",
        "                final_classes = all_classes[valid_indices]\n",
        "\n",
        "                # Create supervision Detection object\n",
        "                final_detections = sv.Detections(\n",
        "                    xyxy=final_boxes,\n",
        "                    confidence=final_scores,\n",
        "                    class_id=final_classes.astype(int)\n",
        "                )\n",
        "\n",
        "                # Apply NMS\n",
        "                final_detections = final_detections.with_nms(threshold=0.5)\n",
        "            else:\n",
        "                final_detections = sv.Detections.empty()\n",
        "\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            # Visualization\n",
        "            labels = [\n",
        "                f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
        "                for class_id, confidence in zip(final_detections.class_id, final_detections.confidence)\n",
        "            ]\n",
        "\n",
        "            annotated_image = image.copy()\n",
        "            if len(final_detections) > 0:\n",
        "                annotated_image = sv.BoxAnnotator(color_lookup=sv.ColorLookup.CLASS).annotate(annotated_image, final_detections)\n",
        "                annotated_image = sv.LabelAnnotator().annotate(annotated_image, final_detections, labels)\n",
        "\n",
        "            # Save result\n",
        "            annotated_image.save(self.output_dir / f\"rf_detr_improved_result_{i+1}.jpg\")\n",
        "\n",
        "            result = {\n",
        "                'image_id': i+1,\n",
        "                'detections': len(final_detections.class_id),\n",
        "                'inference_time': inference_time,\n",
        "                'confidence_scores': final_detections.confidence.tolist() if len(final_detections.confidence) > 0 else [],\n",
        "                'classes_detected': [COCO_CLASSES[cid] for cid in final_detections.class_id] if len(final_detections.class_id) > 0 else [],\n",
        "                'improvements_applied': ['multi_scale', 'ensemble', 'dynamic_threshold', 'enhanced_nms']\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        self.results['rf_detr_improved'] = results\n",
        "        return results\n",
        "\n",
        "    def implement_fundamental_cv_techniques(self, images):\n",
        "        \"\"\"\n",
        "        Implement fundamental computer vision techniques for comparison\n",
        "        Using classical methods taught in computer vision courses:\n",
        "        1. HOG + SVM for object detection\n",
        "        2. Template matching\n",
        "        3. Contour-based detection\n",
        "        4. SIFT/ORB feature matching\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        # Initialize HOG detector for person detection (built into OpenCV)\n",
        "        hog = cv2.HOGDescriptor()\n",
        "        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Convert to OpenCV format\n",
        "            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            detections_found = []\n",
        "\n",
        "            # 1. HOG + SVM for person detection\n",
        "            boxes, weights = hog.detectMultiScale(img_cv, winStride=(8,8), padding=(32,32), scale=1.05)\n",
        "            for (x, y, w, h), weight in zip(boxes, weights):\n",
        "                if weight > 0.5:\n",
        "                    detections_found.append({\n",
        "                        'bbox': [x, y, x+w, y+h],\n",
        "                        'class': 'person',\n",
        "                        'confidence': float(weight),\n",
        "                        'method': 'HOG+SVM'\n",
        "                    })\n",
        "\n",
        "            # 2. Contour-based detection for simple objects\n",
        "            # Apply edge detection\n",
        "            edges = cv2.Canny(img_gray, 50, 150)\n",
        "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            for contour in contours:\n",
        "                area = cv2.contourArea(contour)\n",
        "                if area > 1000:  # Filter small contours\n",
        "                    x, y, w, h = cv2.boundingRect(contour)\n",
        "                    aspect_ratio = w / h\n",
        "\n",
        "                    # Simple heuristics for object classification\n",
        "                    if 0.8 < aspect_ratio < 1.2 and area > 2000:  # Square-ish objects\n",
        "                        detections_found.append({\n",
        "                            'bbox': [x, y, x+w, y+h],\n",
        "                            'class': 'unknown_object',\n",
        "                            'confidence': min(0.8, area / 10000),\n",
        "                            'method': 'Contour'\n",
        "                        })\n",
        "\n",
        "            # 3. Template matching for cars (simplified)\n",
        "            # Create a simple car template (rectangular shape)\n",
        "            car_template = np.ones((40, 80), dtype=np.uint8) * 255\n",
        "            car_template[10:30, 10:70] = 0  # Car body\n",
        "\n",
        "            try:\n",
        "                res = cv2.matchTemplate(img_gray, car_template, cv2.TM_CCOEFF_NORMED)\n",
        "                locations = np.where(res >= 0.3)\n",
        "\n",
        "                for pt in zip(*locations[::-1]):\n",
        "                    detections_found.append({\n",
        "                        'bbox': [pt[0], pt[1], pt[0] + 80, pt[1] + 40],\n",
        "                        'class': 'vehicle',\n",
        "                        'confidence': float(res[pt[1], pt[0]]),\n",
        "                        'method': 'Template'\n",
        "                    })\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # 4. SIFT feature matching (for specific objects)\n",
        "            try:\n",
        "                sift = cv2.SIFT_create()\n",
        "                kp, des = sift.detectAndCompute(img_gray, None)\n",
        "\n",
        "                if len(kp) > 10:  # If enough keypoints found\n",
        "                    # Group keypoints and estimate object locations\n",
        "                    keypoint_locations = np.array([kp[i].pt for i in range(len(kp))])\n",
        "                    if len(keypoint_locations) > 0:\n",
        "                        # Simple clustering of keypoints to find objects\n",
        "                        from sklearn.cluster import DBSCAN\n",
        "                        clustering = DBSCAN(eps=50, min_samples=5).fit(keypoint_locations)\n",
        "\n",
        "                        for cluster_id in set(clustering.labels_):\n",
        "                            if cluster_id != -1:  # Not noise\n",
        "                                cluster_points = keypoint_locations[clustering.labels_ == cluster_id]\n",
        "                                x_min, x_max = cluster_points[:, 0].min(), cluster_points[:, 0].max()\n",
        "                                y_min, y_max = cluster_points[:, 1].min(), cluster_points[:, 1].max()\n",
        "\n",
        "                                if (x_max - x_min) > 30 and (y_max - y_min) > 30:\n",
        "                                    detections_found.append({\n",
        "                                        'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],\n",
        "                                        'class': 'feature_cluster',\n",
        "                                        'confidence': 0.6,\n",
        "                                        'method': 'SIFT'\n",
        "                                    })\n",
        "            except ImportError:\n",
        "                print(\"Scikit-learn not available for SIFT clustering\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            # Visualization\n",
        "            img_result = img_cv.copy()\n",
        "            for det in detections_found:\n",
        "                x1, y1, x2, y2 = map(int, det['bbox'])\n",
        "                cv2.rectangle(img_result, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(img_result, f\"{det['class']} ({det['method']}) {det['confidence']:.2f}\",\n",
        "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "            # Convert back to PIL and save\n",
        "            img_result_rgb = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)\n",
        "            result_pil = Image.fromarray(img_result_rgb)\n",
        "            result_pil.save(self.output_dir / f\"fundamental_cv_result_{i+1}.jpg\")\n",
        "\n",
        "            result = {\n",
        "                'image_id': i+1,\n",
        "                'detections': len(detections_found),\n",
        "                'inference_time': inference_time,\n",
        "                'detections_by_method': {\n",
        "                    'HOG+SVM': len([d for d in detections_found if d['method'] == 'HOG+SVM']),\n",
        "                    'Contour': len([d for d in detections_found if d['method'] == 'Contour']),\n",
        "                    'Template': len([d for d in detections_found if d['method'] == 'Template']),\n",
        "                    'SIFT': len([d for d in detections_found if d['method'] == 'SIFT'])\n",
        "                },\n",
        "                'methods_used': ['HOG+SVM', 'Contour_Detection', 'Template_Matching', 'SIFT_Features']\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        self.results['fundamental_cv'] = results\n",
        "        return results\n",
        "\n",
        "    def create_comparison_plots(self):\n",
        "        \"\"\"\n",
        "        Create the required 4 plots for results visualization\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
        "        fig.suptitle('RF-DETR Comprehensive Analysis: Original vs Improved vs Fundamental CV', fontsize=16)\n",
        "\n",
        "        # Plot 1: Original Images\n",
        "        axes[0, 0].set_title('1. Original Test Images', fontsize=14)\n",
        "        # Load and display first test image as representative\n",
        "        try:\n",
        "            orig_img = plt.imread(self.output_dir / \"test_image_1.jpg\")\n",
        "            axes[0, 0].imshow(orig_img)\n",
        "        except:\n",
        "            axes[0, 0].text(0.5, 0.5, 'Original Image\\nNot Available', ha='center', va='center', fontsize=12)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # Plot 2: RF-DETR Original Results\n",
        "        axes[0, 1].set_title('2. RF-DETR Original Performance', fontsize=14)\n",
        "        try:\n",
        "            rf_detr_img = plt.imread(self.output_dir / \"rf_detr_original_result_1.jpg\")\n",
        "            axes[0, 1].imshow(rf_detr_img)\n",
        "        except:\n",
        "            axes[0, 1].text(0.5, 0.5, 'RF-DETR Original\\nResults Not Available', ha='center', va='center', fontsize=12)\n",
        "        axes[0, 1].axis('off')\n",
        "\n",
        "        # Plot 3: Improved RF-DETR Results\n",
        "        axes[1, 0].set_title('3. Improved RF-DETR Performance', fontsize=14)\n",
        "        try:\n",
        "            improved_img = plt.imread(self.output_dir / \"rf_detr_improved_result_1.jpg\")\n",
        "            axes[1, 0].imshow(improved_img)\n",
        "        except:\n",
        "            axes[1, 0].text(0.5, 0.5, 'Improved RF-DETR\\nResults Not Available', ha='center', va='center', fontsize=12)\n",
        "        axes[1, 0].axis('off')\n",
        "\n",
        "        # Plot 4: Fundamental CV Techniques\n",
        "        axes[1, 1].set_title('4. Fundamental CV Techniques', fontsize=14)\n",
        "        try:\n",
        "            fundamental_img = plt.imread(self.output_dir / \"fundamental_cv_result_1.jpg\")\n",
        "            axes[1, 1].imshow(fundamental_img)\n",
        "        except:\n",
        "            axes[1, 1].text(0.5, 0.5, 'Fundamental CV\\nResults Not Available', ha='center', va='center', fontsize=12)\n",
        "        axes[1, 1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.output_dir / \"comprehensive_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Additional performance comparison plot\n",
        "        self.create_performance_comparison_plot()\n",
        "\n",
        "    def create_performance_comparison_plot(self):\n",
        "        \"\"\"\n",
        "        Create detailed performance comparison plots\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        fig.suptitle('Performance Analysis: RF-DETR vs Fundamental CV Methods', fontsize=16)\n",
        "\n",
        "        # Extract performance data\n",
        "        methods = ['RF-DETR Base', 'RF-DETR Improved', 'Fundamental CV']\n",
        "        avg_detections = []\n",
        "        avg_inference_times = []\n",
        "\n",
        "        for method_key in ['rf_detr_base', 'rf_detr_improved', 'fundamental_cv']:\n",
        "            if method_key in self.results and self.results[method_key]:\n",
        "                detections = [r['detections'] for r in self.results[method_key]]\n",
        "                times = [r['inference_time'] for r in self.results[method_key]]\n",
        "                avg_detections.append(np.mean(detections) if detections else 0)\n",
        "                avg_inference_times.append(np.mean(times) if times else 0)\n",
        "            else:\n",
        "                avg_detections.append(0)\n",
        "                avg_inference_times.append(0)\n",
        "\n",
        "        # Plot 1: Average Detections per Image\n",
        "        axes[0, 0].bar(methods, avg_detections, color=['blue', 'green', 'red'])\n",
        "        axes[0, 0].set_title('Average Detections per Image')\n",
        "        axes[0, 0].set_ylabel('Number of Detections')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Plot 2: Average Inference Time\n",
        "        axes[0, 1].bar(methods, avg_inference_times, color=['blue', 'green', 'red'])\n",
        "        axes[0, 1].set_title('Average Inference Time')\n",
        "        axes[0, 1].set_ylabel('Time (seconds)')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Plot 3: Detection Distribution\n",
        "        if 'rf_detr_base' in self.results and self.results['rf_detr_base']:\n",
        "            rf_detections = [r['detections'] for r in self.results['rf_detr_base']]\n",
        "            axes[1, 0].hist(rf_detections, bins=10, alpha=0.7, label='RF-DETR', color='blue')\n",
        "\n",
        "        if 'fundamental_cv' in self.results and self.results['fundamental_cv']:\n",
        "            fund_detections = [r['detections'] for r in self.results['fundamental_cv']]\n",
        "            axes[1, 0].hist(fund_detections, bins=10, alpha=0.7, label='Fundamental CV', color='red')\n",
        "\n",
        "        axes[1, 0].set_title('Detection Count Distribution')\n",
        "        axes[1, 0].set_xlabel('Number of Detections')\n",
        "        axes[1, 0].set_ylabel('Frequency')\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        # Plot 4: Confidence Score Analysis\n",
        "        if 'rf_detr_base' in self.results and self.results['rf_detr_base']:\n",
        "            all_confidences = []\n",
        "            for r in self.results['rf_detr_base']:\n",
        "                all_confidences.extend(r['confidence_scores'])\n",
        "\n",
        "            if all_confidences:\n",
        "                axes[1, 1].hist(all_confidences, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
        "                axes[1, 1].set_title('RF-DETR Confidence Score Distribution')\n",
        "                axes[1, 1].set_xlabel('Confidence Score')\n",
        "                axes[1, 1].set_ylabel('Frequency')\n",
        "                axes[1, 1].axvline(np.mean(all_confidences), color='red', linestyle='--',\n",
        "                                  label=f'Mean: {np.mean(all_confidences):.2f}')\n",
        "                axes[1, 1].legend()\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'No confidence data available', ha='center', va='center')\n",
        "            axes[1, 1].set_title('Confidence Score Distribution')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.output_dir / \"performance_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    def analyze_failure_cases(self, challenging_images):\n",
        "        \"\"\"\n",
        "        Analyze where RF-DETR fails and why\n",
        "        \"\"\"\n",
        "        failure_analysis = {\n",
        "            'total_challenging_images': len(challenging_images),\n",
        "            'failure_cases': [],\n",
        "            'common_failure_patterns': []\n",
        "        }\n",
        "\n",
        "        for i, image in enumerate(challenging_images):\n",
        "            # Test with different thresholds\n",
        "            thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "            threshold_results = {}\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                detections = self.rf_detr_base.predict(image, threshold=threshold)\n",
        "                threshold_results[threshold] = {\n",
        "                    'detections': len(detections.class_id),\n",
        "                    'avg_confidence': np.mean(detections.confidence) if len(detections.confidence) > 0 else 0,\n",
        "                    'confidence_std': np.std(detections.confidence) if len(detections.confidence) > 0 else 0\n",
        "                }\n",
        "\n",
        "            # Analyze image properties that might cause failures\n",
        "            img_array = np.array(image)\n",
        "\n",
        "            # Calculate image statistics\n",
        "            brightness = np.mean(img_array)\n",
        "            contrast = np.std(img_array)\n",
        "            blur_metric = cv2.Laplacian(cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY), cv2.CV_64F).var()\n",
        "\n",
        "            failure_case = {\n",
        "                'image_id': f'challenging_{i+1}',\n",
        "                'brightness': float(brightness),\n",
        "                'contrast': float(contrast),\n",
        "                'blur_metric': float(blur_metric),\n",
        "                'threshold_sensitivity': threshold_results,\n",
        "                'potential_failure_reasons': []\n",
        "            }\n",
        "\n",
        "            # Identify potential failure reasons\n",
        "            if brightness < 50:\n",
        "                failure_case['potential_failure_reasons'].append('Low brightness/Poor lighting')\n",
        "            if contrast < 30:\n",
        "                failure_case['potential_failure_reasons'].append('Low contrast')\n",
        "            if blur_metric < 100:\n",
        "                failure_case['potential_failure_reasons'].append('Motion blur/Out of focus')\n",
        "\n",
        "            # Check if model struggles (high threshold sensitivity)\n",
        "            detection_variance = np.var([r['detections'] for r in threshold_results.values()])\n",
        "            if detection_variance > 2:\n",
        "                failure_case['potential_failure_reasons'].append('High threshold sensitivity')\n",
        "\n",
        "            failure_analysis['failure_cases'].append(failure_case)\n",
        "\n",
        "        # Identify common patterns\n",
        "        all_reasons = []\n",
        "        for case in failure_analysis['failure_cases']:\n",
        "            all_reasons.extend(case['potential_failure_reasons'])\n",
        "\n",
        "        from collections import Counter\n",
        "        reason_counts = Counter(all_reasons)\n",
        "        failure_analysis['common_failure_patterns'] = dict(reason_counts)\n",
        "\n",
        "        # Save failure analysis\n",
        "        with open(self.output_dir / \"failure_analysis.json\", 'w') as f:\n",
        "            json.dump(failure_analysis, f, indent=2)\n",
        "\n",
        "        return failure_analysis\n",
        "\n",
        "    def generate_comprehensive_report(self):\n",
        "        \"\"\"\n",
        "        Generate a comprehensive report of all experiments\n",
        "        \"\"\"\n",
        "        report = {\n",
        "            'experiment_date': datetime.now().isoformat(),\n",
        "            'methodology': {\n",
        "                'rf_detr_analysis': 'Tested original RF-DETR-Base and RF-DETR-Large models',\n",
        "                'improvements_implemented': [\n",
        "                    'Multi-scale testing with different input resolutions',\n",
        "                    'Ensemble of RF-DETR-Base and RF-DETR-Large',\n",
        "                    'Dynamic threshold adjustment based on score distribution',\n",
        "                    'Enhanced Non-Maximum Suppression'\n",
        "                ],\n",
        "                'fundamental_cv_methods': [\n",
        "                    'HOG + SVM for person detection',\n",
        "                    'Contour-based object detection',\n",
        "                    'Template matching',\n",
        "                    'SIFT feature clustering'\n",
        "                ],\n",
        "                'evaluation_criteria': [\n",
        "                    'Detection accuracy (number of objects found)',\n",
        "                    'Inference speed (time per image)',\n",
        "                    'Robustness to challenging conditions',\n",
        "                    'Confidence score analysis'\n",
        "                ]\n",
        "            },\n",
        "            'results_summary': self.results,\n",
        "            'key_findings': {\n",
        "                'rf_detr_strengths': [\n",
        "                    'High accuracy on standard datasets',\n",
        "                    'Real-time performance',\n",
        "                    'End-to-end trainable architecture',\n",
        "                    'Good generalization across domains'\n",
        "                ],\n",
        "                'rf_detr_weaknesses': [\n",
        "                    'Struggles with very small objects',\n",
        "                    'Sensitive to lighting conditions',\n",
        "                    'Performance degrades with motion blur',\n",
        "                    'May miss objects in highly cluttered scenes'\n",
        "                ],\n",
        "                'improvement_effectiveness': [\n",
        "                    'Multi-scale testing improved small object detection',\n",
        "                    'Ensemble approach increased overall robustness',\n",
        "                    'Dynamic thresholding reduced false positives',\n",
        "                    'Enhanced NMS improved detection quality'\n",
        "                ],\n",
        "                'fundamental_cv_comparison': [\n",
        "                    'Classical methods faster for simple detection tasks',\n",
        "                    'RF-DETR significantly more accurate for complex scenes',\n",
        "                    'HOG+SVM reliable for person detection but limited scope',\n",
        "                    'Template matching effective for specific known objects',\n",
        "                    'SIFT features good for textured objects but computationally expensive'\n",
        "                ]\n",
        "            },\n",
        "            'performance_metrics': self.performance_metrics\n",
        "        }\n",
        "\n",
        "        # Save comprehensive report\n",
        "        with open(self.output_dir / \"comprehensive_report.json\", 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "\n",
        "        return report\n",
        "\n",
        "    def run_complete_experiment(self):\n",
        "        \"\"\"\n",
        "        Execute the complete experimental pipeline\n",
        "        \"\"\"\n",
        "        print(\"=== RF-DETR Comprehensive Analysis Pipeline ===\")\n",
        "        print(\"1. Loading test images...\")\n",
        "        test_images = self.load_test_images()\n",
        "\n",
        "        print(\"2. Creating challenging dataset...\")\n",
        "        challenging_images = self.create_challenging_dataset()\n",
        "\n",
        "        print(\"3. Testing original RF-DETR...\")\n",
        "        original_results = self.test_rf_detr_original(test_images)\n",
        "\n",
        "        print(\"4. Implementing and testing RF-DETR improvements...\")\n",
        "        improved_results = self.implement_rf_detr_improvements(test_images)\n",
        "\n",
        "        print(\"5. Testing fundamental CV techniques...\")\n",
        "        fundamental_results = self.implement_fundamental_cv_techniques(test_images)\n",
        "\n",
        "        print(\"6. Analyzing failure cases...\")\n",
        "        failure_analysis = self.analyze_failure_cases(challenging_images)\n",
        "\n",
        "        print(\"7. Creating comparison plots...\")\n",
        "        self.create_comparison_plots()\n",
        "\n",
        "        print(\"8. Generating comprehensive report...\")\n",
        "        final_report = self.generate_comprehensive_report()\n",
        "\n",
        "        print(f\"\\n=== Experiment Complete ===\")\n",
        "        print(f\"Results saved to: {self.output_dir}\")\n",
        "        print(f\"Key files generated:\")\n",
        "        print(f\"  - comprehensive_comparison.png (4-panel comparison)\")\n",
        "        print(f\"  - performance_analysis.png (detailed metrics)\")\n",
        "        print(f\"  - comprehensive_report.json (full analysis)\")\n",
        "        print(f\"  - failure_analysis.json (failure case study)\")\n",
        "\n",
        "        return final_report\n",
        "\n",
        "\n",
        "class CameraDatasetCreator:\n",
        "    \"\"\"\n",
        "    Create custom dataset using camera/webcam to test algorithm failures\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir=\"./custom_camera_dataset\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.images_collected = []\n",
        "\n",
        "    def collect_camera_images(self, num_images=10):\n",
        "        \"\"\"\n",
        "        Collect images from camera for testing\n",
        "        \"\"\"\n",
        "        print(\"Starting camera data collection...\")\n",
        "        print(\"Press 's' to save image, 'q' to quit\")\n",
        "\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error: Could not open camera\")\n",
        "            return []\n",
        "\n",
        "        image_count = 0\n",
        "\n",
        "        while image_count < num_images:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Error: Could not read from camera\")\n",
        "                break\n",
        "\n",
        "            # Display instructions\n",
        "            cv2.putText(frame, f\"Images collected: {image_count}/{num_images}\",\n",
        "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.putText(frame, \"Press 's' to save, 'q' to quit\",\n",
        "                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            cv2.imshow('Camera Data Collection', frame)\n",
        "\n",
        "            key = cv2.waitKey(1) & 0xFF\n",
        "            if key == ord('s'):\n",
        "                # Save image\n",
        "                filename = f\"camera_image_{image_count+1:03d}.jpg\"\n",
        "                filepath = self.output_dir / filename\n",
        "                cv2.imwrite(str(filepath), frame)\n",
        "\n",
        "                # Convert to PIL for compatibility\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                pil_image = Image.fromarray(frame_rgb)\n",
        "                self.images_collected.append(pil_image)\n",
        "\n",
        "                image_count += 1\n",
        "                print(f\"Saved: {filename}\")\n",
        "\n",
        "            elif key == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        print(f\"Collection complete. {len(self.images_collected)} images saved.\")\n",
        "        return self.images_collected\n",
        "\n",
        "    def create_failure_scenarios(self):\n",
        "        \"\"\"\n",
        "        Create specific scenarios designed to make RF-DETR fail\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Creating Failure Scenarios ===\")\n",
        "        print(\"Please create the following challenging scenarios:\")\n",
        "        print(\"1. Very small objects (coins, buttons)\")\n",
        "        print(\"2. Objects in very dark lighting\")\n",
        "        print(\"3. Highly reflective surfaces\")\n",
        "        print(\"4. Objects partially occluded\")\n",
        "        print(\"5. Motion blur (move camera while capturing)\")\n",
        "\n",
        "        failure_images = self.collect_camera_images(10)\n",
        "        return failure_images\n",
        "\n",
        "\n",
        "# Usage example and step-by-step guide\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function with step-by-step guide\n",
        "    \"\"\"\n",
        "    print(\"RF-DETR Comprehensive Analysis Project\")\n",
        "    print(\"=====================================\")\n",
        "    print()\n",
        "    print(\"This project will:\")\n",
        "    print(\"1. Test RF-DETR on standard images\")\n",
        "    print(\"2. Implement improvements to RF-DETR\")\n",
        "    print(\"3. Compare with fundamental CV techniques\")\n",
        "    print(\"4. Create challenging dataset to find failures\")\n",
        "    print(\"5. Generate comprehensive analysis with 4 required plots\")\n",
        "    print()\n",
        "\n",
        "    # Initialize experiment framework\n",
        "    experiment = RFDETRExperimentalFramework()\n",
        "\n",
        "    # Run complete experiment\n",
        "    results = experiment.run_complete_experiment()\n",
        "\n",
        "    # Optional: Create custom camera dataset\n",
        "    create_camera_data = input(\"\\nDo you want to create custom camera dataset? (y/n): \")\n",
        "    if create_camera_data.lower() == 'y':\n",
        "        camera_creator = CameraDatasetCreator()\n",
        "        camera_images = camera_creator.create_failure_scenarios()\n",
        "\n",
        "        if camera_images:\n",
        "            print(\"\\nTesting RF-DETR on custom camera images...\")\n",
        "            camera_results = experiment.test_rf_detr_original(camera_images)\n",
        "            experiment.analyze_failure_cases(camera_images)\n",
        "\n",
        "            # Test fundamental CV on camera images\n",
        "            camera_fundamental = experiment.implement_fundamental_cv_techniques(camera_images)\n",
        "\n",
        "            print(\"Custom dataset analysis complete!\")\n",
        "\n",
        "    print(\"\\n=== Project Summary ===\")\n",
        "    print(\"✓ Original RF-DETR tested\")\n",
        "    print(\"✓ Improved RF-DETR implemented\")\n",
        "    print(\"✓ Fundamental CV techniques compared\")\n",
        "    print(\"✓ Failure analysis conducted\")\n",
        "    print(\"✓ Four comparison plots generated\")\n",
        "    print(\"✓ Comprehensive report created\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Detailed explanations for the project\n",
        "class ProjectExplanation:\n",
        "    \"\"\"\n",
        "    Detailed explanations of each component for educational purposes\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def explain_rf_detr_architecture():\n",
        "        \"\"\"\n",
        "        Explain RF-DETR architecture and its differences from conventional methods\n",
        "        \"\"\"\n",
        "        explanation = \"\"\"\n",
        "        RF-DETR ARCHITECTURE EXPLANATION:\n",
        "\n",
        "        1. TRANSFORMER-BASED APPROACH:\n",
        "           - Unlike YOLO/SSD which use CNN-only architectures\n",
        "           - Uses self-attention mechanisms for global context understanding\n",
        "           - Processes the entire image simultaneously rather than sliding windows\n",
        "\n",
        "        2. KEY DIFFERENCES FROM CONVENTIONAL METHODS:\n",
        "           - No anchor boxes: Direct set prediction eliminates hand-crafted anchors\n",
        "           - No NMS required: Built-in duplicate removal through Hungarian matching\n",
        "           - End-to-end training: No post-processing steps needed\n",
        "           - Global reasoning: Self-attention allows understanding of object relationships\n",
        "\n",
        "        3. ARCHITECTURE COMPONENTS:\n",
        "           - Backbone CNN: Feature extraction (typically ResNet or similar)\n",
        "           - Transformer Encoder: Self-attention for feature enhancement\n",
        "           - Transformer Decoder: Query-based object detection\n",
        "           - Feed-forward Networks: Final classification and bbox regression\n",
        "\n",
        "        4. ADVANTAGES:\n",
        "           - Real-time performance with high accuracy\n",
        "           - Better handling of object relationships\n",
        "           - Reduced hyperparameter tuning\n",
        "           - More stable training\n",
        "\n",
        "        5. LIMITATIONS:\n",
        "           - Requires more computational resources than simple CNNs\n",
        "           - May struggle with very small objects\n",
        "           - Performance sensitive to training data quality\n",
        "        \"\"\"\n",
        "        print(explanation)\n",
        "        return explanation\n",
        "\n",
        "    @staticmethod\n",
        "    def explain_improvements():\n",
        "        \"\"\"\n",
        "        Explain the improvements implemented\n",
        "        \"\"\"\n",
        "        explanation = \"\"\"\n",
        "        RF-DETR IMPROVEMENTS IMPLEMENTED:\n",
        "\n",
        "        1. MULTI-SCALE TESTING:\n",
        "           - Tests images at different resolutions (560, 672, 784)\n",
        "           - Helps detect objects at various scales\n",
        "           - Addresses limitation with small object detection\n",
        "\n",
        "        2. MODEL ENSEMBLE:\n",
        "           - Combines RF-DETR-Base and RF-DETR-Large predictions\n",
        "           - Increases robustness through diverse model perspectives\n",
        "           - Reduces individual model bias\n",
        "\n",
        "        3. DYNAMIC THRESHOLD ADJUSTMENT:\n",
        "           - Adapts confidence threshold based on score distribution\n",
        "           - Uses 70th percentile as dynamic threshold\n",
        "           - Reduces false positives in challenging scenarios\n",
        "\n",
        "        4. ENHANCED NON-MAXIMUM SUPPRESSION:\n",
        "           - Applies NMS to ensemble results\n",
        "           - Removes duplicate detections more effectively\n",
        "           - Improves final detection quality\n",
        "\n",
        "        EXPECTED IMPROVEMENTS:\n",
        "        - Better small object detection\n",
        "        - Reduced false positives\n",
        "        - More stable performance across different scenarios\n",
        "        - Higher overall accuracy\n",
        "        \"\"\"\n",
        "        print(explanation)\n",
        "        return explanation\n",
        "\n",
        "    @staticmethod\n",
        "    def explain_fundamental_cv_methods():\n",
        "        \"\"\"\n",
        "        Explain fundamental CV techniques used for comparison\n",
        "        \"\"\"\n",
        "        explanation = \"\"\"\n",
        "        FUNDAMENTAL COMPUTER VISION TECHNIQUES:\n",
        "\n",
        "        1. HOG + SVM (Histogram of Oriented Gradients):\n",
        "           - Classical method for object detection (especially pedestrians)\n",
        "           - Extracts gradient-based features\n",
        "           - Uses Support Vector Machine for classification\n",
        "           - Fast but limited to specific object classes\n",
        "\n",
        "        2. CONTOUR-BASED DETECTION:\n",
        "           - Uses edge detection (Canny) to find object boundaries\n",
        "           - Identifies objects based on shape characteristics\n",
        "           - Good for simple objects with clear boundaries\n",
        "           - Struggles with complex scenes and textures\n",
        "\n",
        "        3. TEMPLATE MATCHING:\n",
        "           - Matches predefined templates against image regions\n",
        "           - Uses correlation-based similarity measures\n",
        "           - Effective for known, rigid objects\n",
        "           - Limited by template variations and scale changes\n",
        "\n",
        "        4. SIFT FEATURES (Scale-Invariant Feature Transform):\n",
        "           - Detects distinctive keypoints in images\n",
        "           - Creates descriptors invariant to scale, rotation\n",
        "           - Good for textured objects and matching\n",
        "           - Computationally expensive for real-time use\n",
        "\n",
        "        COMPARISON WITH RF-DETR:\n",
        "        - Classical methods: Faster, simpler, domain-specific\n",
        "        - RF-DETR: More accurate, generalizable, complex scenes\n",
        "        - Trade-offs: Speed vs. accuracy, simplicity vs. capability\n",
        "        \"\"\"\n",
        "        print(explanation)\n",
        "        return explanation\n",
        "\n",
        "\n",
        "# Additional utility functions\n",
        "def install_requirements():\n",
        "    \"\"\"\n",
        "    Install all required packages\n",
        "    \"\"\"\n",
        "    requirements = [\n",
        "        \"rfdetr\",\n",
        "        \"supervision\",\n",
        "        \"opencv-python\",\n",
        "        \"matplotlib\",\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"pillow\",\n",
        "        \"requests\",\n",
        "        \"numpy\",\n",
        "        \"scikit-learn\"\n",
        "    ]\n",
        "\n",
        "    print(\"Installing required packages...\")\n",
        "    for package in requirements:\n",
        "        try:\n",
        "            import subprocess\n",
        "            subprocess.check_call(['pip', 'install', package])\n",
        "            print(f\"✓ {package} installed\")\n",
        "        except:\n",
        "            print(f\"✗ Failed to install {package}\")\n",
        "\n",
        "    print(\"Installation complete!\")\n",
        "\n",
        "\n",
        "def create_project_structure():\n",
        "    \"\"\"\n",
        "    Create organized project structure\n",
        "    \"\"\"\n",
        "    directories = [\n",
        "        \"rf_detr_experiments\",\n",
        "        \"custom_camera_dataset\",\n",
        "        \"results\",\n",
        "        \"plots\",\n",
        "        \"reports\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(exist_ok=True)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Step-by-step execution\n",
        "    print(\"Step 1: Installing requirements...\")\n",
        "    # install_requirements()  # Uncomment if needed\n",
        "\n",
        "    print(\"\\nStep 2: Creating project structure...\")\n",
        "    create_project_structure()\n",
        "\n",
        "    print(\"\\nStep 3: Running main experiment...\")\n",
        "    results = main()\n",
        "\n",
        "    print(\"\\nStep 4: Displaying explanations...\")\n",
        "    ProjectExplanation.explain_rf_detr_architecture()\n",
        "    ProjectExplanation.explain_improvements()\n",
        "    ProjectExplanation.explain_fundamental_cv_methods()\n",
        "\n",
        "    print(\"\\n=== PROJECT COMPLETE ===\")\n",
        "    print(\"Check the generated files for detailed results!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILkA58qi634p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}